recall
[0.14526438 0.07486034 0.09888801 0.22895162 0.3417203  0.14061317
 0.29694929 0.14274795 0.12932039 0.17142857 0.31972051]
precision
[0.11343013 0.01772487 0.1177305  0.23807061 0.41845052 0.08467236
 0.45976894 0.13399103 0.08356336 0.15065334 0.33101559]
F1_Score
[0.12738854 0.0286631  0.10748975 0.23342209 0.37621291 0.10569742
 0.36084253 0.13823094 0.10152439 0.16037093 0.32527002]
accuracy_norm
0.25527616239386247
accuracy
18700
cfsn_mtrx
[[ 250   50   45  196   55   65  366  306   48  137  203]
 [  80   67   63   46    5   51  201   74  207   51   50]
 [ 116  169  249  224  102  254  797  167  189  125  126]
 [  87  362  376 1841  606 1263  784  559  257  422 1484]
 [ 353  404  157 1135 4672 1748  754  425  778  560 2686]
 [ 177  252   79  407  898  743  586  210  490  343 1099]
 [ 466  842  464 1605  837 1236 4497 1544  844  669 2140]
 [  84  485   82  731  457  199  533  747  301  436 1178]
 [ 102  308   80  169  250  234  318  341  333   79  361]
 [ 293  267  197  469  154  124  515  569   56  588  198]
 [ 196  574  323  910 3129 2858  430  633  482  493 4713]]
labels
['cel' 'cla' 'flu' 'gac' 'gel' 'org' 'pia' 'sax' 'tru' 'vio' 'voi']
