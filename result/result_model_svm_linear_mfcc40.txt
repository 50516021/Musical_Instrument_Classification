recall
[0.23474724 0.16312849 0.14217633 0.19960204 0.27450263 0.13626041
 0.21737982 0.1559335  0.13281553 0.18046647 0.15772336]
precision
[0.07136548 0.02652616 0.0628732  0.24541284 0.36479393 0.10362694
 0.41518476 0.11594203 0.0669145  0.10852034 0.34006143]
F1_Score
[0.10945543 0.04563213 0.08718948 0.22014951 0.31327212 0.117724
 0.28535518 0.1329965  0.08899297 0.13553755 0.21549727]
accuracy_norm
0.19630327354137658
accuracy
14380
cfsn_mtrx
[[ 404  151  109  164   92   52  194  237  126  131   61]
 [ 102  146   94   33   13   50  175   87  101   92    2]
 [ 128  415  358  193  156  137  397  305  219  149   61]
 [ 397  693  505 1605  878  954  691  650  397  408  863]
 [1076  662  562 1079 3753 1368  771  805 1048  846 1702]
 [ 451  334  328  448  656  720  545  375  434  475  518]
 [1222 1333 1671 1156  944 1068 3292 1636  903 1217  702]
 [ 413  387  504  382  439  384  537  816  372  657  342]
 [ 175  284  459   86  171  158  296  299  342  167  138]
 [ 363  400  185  249  283   85  384  506  233  619  123]
 [ 930  699  919 1145 2903 1972  647 1322  936  943 2325]]
labels
['cel' 'cla' 'flu' 'gac' 'gel' 'org' 'pia' 'sax' 'tru' 'vio' 'voi']
