recall
[0.22777455 0.12960894 0.13423352 0.15010571 0.23398186 0.10938683
 0.19664554 0.12956239 0.13009709 0.16297376 0.15256767]
precision
[0.06118308 0.01882506 0.06061693 0.18194151 0.33257095 0.08915625
 0.38405984 0.10195489 0.06272234 0.10202592 0.31458945]
F1_Score
[0.09645669 0.03287516 0.08351866 0.16449744 0.27469838 0.09824084
 0.26011005 0.1141126  0.08463871 0.12549108 0.20548196]
accuracy_norm
0.17240014197176945
accuracy
12629
cfsn_mtrx
[[ 392  203  119  220   88   81  183  203   73  109   50]
 [ 150  116  109   77   12   32  143   69  112   61   14]
 [ 211  309  338  222  133  167  468  282  192  135   61]
 [ 448  543  813 1207  829  795  916  717  385  566  822]
 [1198  708  699  921 3199 1392  782  960 1204  879 1730]
 [ 554  375  317  452  717  578  498  377  517  379  520]
 [1197 1710 1379 1575  984  984 2978 1401  919 1095  922]
 [ 311  583  294  487  512  330  461  678  440  577  560]
 [ 194  381  286  159  228  141  280  264  335  153  154]
 [ 643  464  275  307  198  150  303  295  169  559   67]
 [1109  770  947 1007 2719 1833  742 1404  995  966 2249]]
labels
['cel' 'cla' 'flu' 'gac' 'gel' 'org' 'pia' 'sax' 'tru' 'vio' 'voi']
